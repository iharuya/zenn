---
title: "Notionデータをベクトル化してChatGPTに食わせてビジネスの相談相手にする方法"
emoji: "💡"
type: "tech"
topics:
  - "langchain"
  - "llm"
  - "bizdev"
published: true
published_at: "2023-05-28 21:24"
---

# 追記：公式サポートされました

いつの日か、この記事でやったような「ワークスペースをAIに読みこませる」ことは公式の機能としてリリースされていました。

https://www.notion.com/ja/product/ai

以下供養。

---

今やどんな規模のビジネスでもLLMを活用するケースが増える中、毎回プロンプトに自社の情報や背景を入力するのは手間がかかります。

プロンプトのテンプレートを用意するのも、ファインチューニングするのも大変です。今回は別のアプローチとして、Notionのデータを直接利用する試みをしました。

ここでは、Notionを更新していけば勝手にAIも自分たちのビジネスへの理解を更新するような仕組みを作っていきます。ビジネス用途に限らず、Notionを使っている人は参考にしてみてください。

# GenStation (サンプルプロジェクト)
ためしにGenStationという仮想的な新規AIサービスのNotionを作ってみました。

![](https://storage.googleapis.com/zenn-user-upload/21f46b8a6289-20230528.png)

現在、MVPを知り合いに共有し、フィードバックを得ているところだと思ってください。
タスクのデータベースを作成し、ローンチに向けての計画を建てているところです。

各タスクはページに紐付けられていていて、このように説明があったりします。
![](https://storage.googleapis.com/zenn-user-upload/ca38a62448a6-20230528.png)

とまあサンプルですのでこの程度ですが、実際のビジネスでこれの何十倍の規模のデータがあったとしても対応できます。

# 実装
## 実装の概要
エージェントの作成やNotion連携に[LangChain](https://python.langchain.com/en/latest/index.html)を利用します。Notionのテキストデータをそのままプロンプトに入れるわけには行かないので、質問に応じて関連部分を引っ張ってこれるようにします。これをリトリーバーと呼び、今回は[Chroma](https://docs.trychroma.com/)とエンベディングはOpenAIのものを使いました。利用するLLMはOpenAIのgpt-4です。

リトリーバー（Retriever）の詳しい説明は以下をご覧ください。
https://tech.acesinc.co.jp/entry/2023/03/31/121001

今回はNotion連携がメインなので、細かな精度向上テクニックは省略します。

## デモ
Python（Jupyter Notebook）を使った実装の例です。

```python
!pip install -qU langchain openai tiktoken chromadb
```
### Notionデータをエクスポート
今回は手動でデータをエクスポートします。対象とするNotionトップページの右上の「…」からエクスポートをしてください。
![](https://storage.googleapis.com/zenn-user-upload/87f6d29aa5cb-20230528.png)
zipファイルがダウンロードされるので、それをPythonの実行ファイルがある場所に移動してください。
以下では、そのzipファイルを展開して読み込みます。

```python
import shutil
from langchain.document_loaders import NotionDirectoryLoader
shutil.unpack_archive("gen-station-notion.zip", "gen-station-notion")
loader = NotionDirectoryLoader("gen-station-notion")
docs = loader.load()
```
docsを見ると、それぞれのNotionのページごとにDocumentオブジェクトが作成されているのがわかると思います。

別の方法として、Notionのデータベースを直接APIから取得する方法もあります。詳しくは[LangChainのドキュメント](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notiondb.html?highlight=notion)をご覧ください。

### リトリーバーの作成
まずはデータをチャンクに分割します
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(docs)
print("\n".join([t.page_content for t in texts[:5]]))
```

EmbeddingにOpenAIのものを利用するので、[OpenAIのAPIキー](https://platform.openai.com/account/api-keys)を設定します
```python
from getpass import getpass
OPENAI_API_KEY = getpass("OpenAI API Key: ")
```

Chromaでベクトルデータベースを作ります。
```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
db = Chroma.from_documents(documents=texts, embedding=embeddings)
db.as_retriever().get_relevant_documents("ローンチの期限は？")
```
これを実行すると、ローンチのタスクのドキュメントを1番関連性の高いデータとして引っ張ってきてくれます。

なお上記コードでのベクトルデータベースはインメモリですが、[任意の場所に書き込んで永続化](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html#persistance)もできます

### エージェントの作成
まずはGPT-4に先ほど作成したリトリーバーを使ってもらいましょう。
```python
from langchain.chat_models import ChatOpenAI
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain.chains import RetrievalQA

llm = ChatOpenAI(
  openai_api_key=OPENAI_API_KEY,
  model_name='gpt-4', # or 'gpt-3.5-turbo'
  temperature=0.5
)
qa = RetrievalQA.from_chain_type(
  llm=llm,
  chain_type="stuff",
  retriever=db.as_retriever(search_kwargs={"k": 10})
)
qa.run("GenStationのローンチに向けて、足りないタスクをいくつか提案してください。")
```
マーケティング戦略の不足や、法遵守の確認、開発系ではセキュリティ対策が十分か指摘してきました。確かにGenerative AIでコンテンツを量産できるプラットフォームを作る場合、著作権やプライバシー問題にセンシティブにならなきゃいけないなぁという発見がありました。

ではこれをツールとして組み込まれたエージェントを作りましょう。
```python
from langchain.agents import Tool
from langchain.agents import initialize_agent
from langchain.agents import AgentType

tools = [
  Tool(
    name='GenStation内部Notion資料',
    func=qa.run,
    description=(
      'GenStationの成長戦略を考えるときに参照する内部資料'
    )
  )
]

conversational_memory = ConversationBufferWindowMemory(
  memory_key='chat_history',
  k=10,
  return_messages=True
)
agent = initialize_agent(
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    tools=tools,
    llm=llm,
    verbose=True,
    max_iterations=3,
    early_stopping_method='generate',
    memory=conversational_memory
)
```

### 話してみる

すると、以下のような質問に対してはNotionデータを参照しないですぐに答えてくれます。
```python
agent("私はGenStationというサービスを1人で作っています。相談相手になってください。")
# Answer: もちろん、GenStationについての相談に乗ります。どのような質問や懸念がありますか？
```
続けて、ちょっとナイーブな質問をしてみましょう。
```python
agent("次に僕は何をすればいい？")
```
>次のステップは、以下のタスクに取り組むことです。
>1. Next.js 13に関する調査を行い、最新のトレンドについて理解を深める。公式ドキュメントを参照し、Next.js 12から13への変更点を把握する。
>2. Next.js 12で作成されたMVPをNext.js 13に移行する。この際、App Routerを利用するようにプロジェクトを更新する。
>3. 5人の別領域の投資家と話し、ビジョンを伝え、MVPを使ってもらう。彼らからアドバイスを受け取り、人的資本を蓄える。
>4. 会話、画像生成、動画生成にそれぞれ異なるAIモデルを利用し、利用量に応じてGemを消費する仕組みを実装する。
>5. Gemの購入にStripeを使用し、購入機能を実装する。
>これらのタスクを進めることで、GenStationの開発を効果的に進めることができます。

すでにMVPは完成していることや、従量課金制にしようとしていることなどを読み取っています。開発だけでなく、ビジネスサイドにも注目しています。なかなか妥当な提案に思えませんか？

# 終わりに

NotionデータをGPT-4に食わせて、有益なビジネスのアドバイスを得ることができました。
更に精度を良くする方法はいくらでもありますし、これからどんどん応答速度が上がり、長期的に見ればコストは絶対安くなっていきます。そうすれば、非常に有能で勤勉な壁打ち相手として重宝するようになるでしょう。

Notionもページ全体の内容をLLMが汲み取ってアイディアを持ちかけてくるようになったら面白そうだなぁなんて思いました。

使える知能はどんどん使っていきたい！
